{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigeek/fitting-covid-19/blob/main/models/LSTM/LSTM_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc1Ov3QWa60l"
      },
      "source": [
        "import pickle\n",
        "import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from numpy import array\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly as py\n",
        "from matplotlib import rcParams\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "import math\n",
        "import pickle\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import folium\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from itertools import cycle\n",
        "sns.set()\n",
        "matplotlib.use('nbagg')\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJqjyEqyfN6a"
      },
      "source": [
        "!pip install --upgrade covsirphy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpGD1-Rca60p"
      },
      "source": [
        "import covsirphy as cs\n",
        "# Download datasets\n",
        "data_loader = cs.DataLoader(\"input\")\n",
        "jhu_data = data_loader.jhu()\n",
        "population_data = data_loader.population()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFWR4PQ-JCuf"
      },
      "source": [
        "#WORLD: G20 countries\n",
        "train = jhu_data.cleaned()\n",
        "days_moving_average = 3\n",
        "total_data = []\n",
        "countries = [\"Russia\", \"Italy\", \"United Kingdom\", \"France\", \"Spain\", \"Germany\", \"Poland\", \"Ukraine\", \"Czech Republic\", \"Netherlands\"]\n",
        "\n",
        "for country in countries:\n",
        "  try:\n",
        "    d, _ = jhu_data.records(country=country,auto_complement=False)\n",
        "    s = cs.Scenario(jhu_data, population_data, country=country)\n",
        "    diff = s.records_diff(variables=[\"Confirmed\"], window=days_moving_average, show_figure=False)\n",
        "    d[\"Country\"] = country\n",
        "    d[\"New Confirmed\"] = diff.reset_index()[\"Confirmed\"]\n",
        "    d = d.loc[:, [\"Date\",\t\"Infected\",\t\"Fatal\",\t\"Recovered\", \"Country\", \"New Confirmed\",\t\"Confirmed\"]]\n",
        "    total_data.append(d)\n",
        "    print(\"inserted\" + \" \" +str(country))\n",
        "  except:\n",
        "    print(country + \": no recovered\")\n",
        "\n",
        "train_df = pd.concat(total_data)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4rkyMrmuHv3"
      },
      "source": [
        "# ITALY\n",
        "italy_data = pd.read_csv(\"https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-andamento-nazionale/dpc-covid19-ita-andamento-nazionale.csv\")\n",
        "days_moving_average = 3\n",
        "train_df, _ = jhu_data.records(\"Italy\",auto_complement=False)\n",
        "s = cs.Scenario(jhu_data, population_data, country=\"Italy\", auto_complement=False)\n",
        "diff = s.records_diff(variables=[\"Confirmed\"], window=days_moving_average, show_figure=False)\n",
        "train_df[\"Hospitalized\"] = italy_data['totale_ospedalizzati']\n",
        "train_df[\"New Confirmed\"] = diff.reset_index()[\"Confirmed\"]\n",
        "train_df = train_df.loc[:, [\"Date\",\t\"Infected\",\t\"Fatal\",\"Recovered\", \"New Confirmed\",\t\"Confirmed\", \"Hospitalized\"]]\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnulmrGJxFcK"
      },
      "source": [
        "def my_create_train_dataset(target, n_steps, train, pivot_date):\n",
        "  train = train.query(\"ObservationDate<\"+pivot_date)\n",
        "  x, y =[], []\n",
        "  sequence = list(train[target])\n",
        "  for i in range(len(sequence)):\n",
        "      end_ix = i + n_steps\n",
        "      if end_ix > len(sequence) - 1:\n",
        "          break\n",
        "      seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "      if(seq_y != 0):\n",
        "         x.append(seq_x)\n",
        "         y.append(seq_y)\n",
        "  return array(x), array(y)\n",
        "\n",
        "def my_create_test_dataset(target, n_steps, train, pivot_date):\n",
        "    train = train.query(\"ObservationDate<\"+pivot_date)\n",
        "    x = []\n",
        "    sequence = train[target].values\n",
        "    x.append(sequence[len(sequence)-n_steps:len(sequence)+1])\n",
        "    return x\n",
        "\n",
        "def pred(model, data):\n",
        "    y_pred = model.predict(data)\n",
        "    return y_pred\n",
        "\n",
        "def my_forcast(model, data, start_date, num_days, n_steps):\n",
        "    \"\"\"\n",
        "    Utility method for Forcasting\n",
        "    model - trained model on Confirmed/Deaths data\n",
        "    start_date - Starting date of forcasting\n",
        "    num_days - Number of days for which forcasting is required\n",
        "    \"\"\"\n",
        "    res_ = dict()\n",
        "    for i in range(len(data)):\n",
        "        res_[i] = []\n",
        "    y_pred = pred(model, data)\n",
        "    dates = []\n",
        "    date1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "\n",
        "    for j in range(1, num_days+1):\n",
        "        for i in range(len(data)):\n",
        "            cur_window = list(data[i][0][1: n_steps+1])\n",
        "            res_[i].append(cur_window[-1])\n",
        "            cur_window.append(y_pred[i])\n",
        "            data[i][0] = cur_window\n",
        "        y_pred = pred(model, data)\n",
        "        dates.append(date1.strftime(\"%Y-%m-%d\"))\n",
        "        date1 += relativedelta(days=1)\n",
        "    res = pd.DataFrame(pd.DataFrame(res_).values.T)\n",
        "    res.columns = dates\n",
        "    return res\n",
        "\n",
        "def my_convert_predictions(res_nc, test, pivot_date, end_date):\n",
        "    test = test.query(\"Date>=\"+pivot_date)\n",
        "    test = test.query(\"Date<=\"+end_date)\n",
        "    pred_nc =[]\n",
        "    for i in range(len(test)):\n",
        "      date = datetime.datetime.strftime(test.iloc[i]['Date'].date(), format=\"%Y-%m-%d\")\n",
        "      pred_nc.append(res_nc[date])\n",
        "    test[\"Hospitalized LSTM\"] = pred_nc\n",
        "    results = test\n",
        "    return results\n",
        "\n",
        "#WORLD\n",
        "def pred(model, data):\n",
        "    y_pred = model.predict(data)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def forcast(model, data, start_date, num_days, n_steps, regs):\n",
        "    \"\"\"\n",
        "    Utility method for Forcasting\n",
        "    model - trained model on Confirmed/Deaths data\n",
        "    start_date - Starting date of forcasting\n",
        "    num_days - Number of days for which forcasting is required\n",
        "    \"\"\"\n",
        "    res_ = dict()\n",
        "    for i in range(len(data)):\n",
        "        res_[i] = []\n",
        "    y_pred = pred(model, data)\n",
        "    dates = []\n",
        "    date1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "\n",
        "    for j in range(1, num_days+1):\n",
        "        for i in range(len(data)):\n",
        "            cur_window = list(data[i][0][1: n_steps+1])\n",
        "            res_[i].append(cur_window[-1])\n",
        "            cur_window.append(y_pred[i])\n",
        "            data[i][0] = cur_window\n",
        "        y_pred = pred(model, data)\n",
        "        dates.append(date1.strftime(\"%Y-%m-%d\"))\n",
        "        date1 += relativedelta(days=1)\n",
        "    res = pd.DataFrame(pd.DataFrame(pd.DataFrame(res_).values.T))\n",
        "    res.columns = dates\n",
        "    res['Country/State'] = regs\n",
        "    return res\n",
        "\n",
        "def create_train_dataset(target, n_steps, train, pivot_date,\n",
        "                         unique_regions, states_per_regions):\n",
        "    train = train.query(\"ObservationDate<\"+pivot_date)\n",
        "    x, y =[], []\n",
        "    for k in tqdm(range(len(unique_regions))):\n",
        "        for state in states_per_regions[k]:\n",
        "            temp = train[(train['Country/Region'] == unique_regions[k])]\n",
        "            sequence = list(temp[target])\n",
        "            for i in range(len(sequence)):\n",
        "                end_ix = i + n_steps\n",
        "                if end_ix > len(sequence) - 1:\n",
        "                    break\n",
        "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "                if(seq_y != 0):\n",
        "                    x.append(seq_x)\n",
        "                    y.append(seq_y)\n",
        "    return array(x), array(y)\n",
        "\n",
        "def create_test_dataset_new_c(target, n_steps, train,pivot_date, unique_regions,\n",
        "                        states_per_regions):\n",
        "    train = train.query(\"ObservationDate<\"+pivot_date)\n",
        "    x, regs = [], []\n",
        "    for k in tqdm(range(len(unique_regions))):\n",
        "        for state in states_per_regions[k]:\n",
        "            temp = train[(train['Country/Region'] == unique_regions[k])]\n",
        "            sequence = temp[target].values\n",
        "            x.append(sequence[len(sequence)-n_steps:len(sequence)+1])\n",
        "            regs.append((unique_regions[k],state))  \n",
        "    return x, regs\n",
        "\n",
        "\n",
        "def create_test_dataset(target, n_steps, train,pivot_date, unique_regions,\n",
        "                        states_per_regions):\n",
        "    \"\"\"\n",
        "    Function to create test dataset\n",
        "    our supervised probem is now given last 7 days data predict \n",
        "    the no of cases for 8th day;\n",
        "    target : 'Confirmed'/'Deaths'\n",
        "    \"\"\"\n",
        "\n",
        "    train = train.query(\"ObservationDate<\"+pivot_date)\n",
        "    x, regs = [], []\n",
        "    for k in tqdm(range(len(unique_regions))):\n",
        "        for state in states_per_regions[k]:\n",
        "            temp = train[(train['Country/Region'] == unique_regions[k])]\n",
        "            sequence = temp[target].values\n",
        "            x.append(sequence[len(sequence)-n_steps:len(sequence)+1])\n",
        "            regs.append((unique_regions[k],state))  \n",
        "    return x, regs\n",
        "\n",
        "def list_per_region(train):\n",
        "  # Creating list of all regions of all counntries\n",
        "    unique_regions = train['Country/Region'].unique()\n",
        "    states_per_regions = []\n",
        "    for reg in tqdm(unique_regions):\n",
        "        states_per_regions.append(\n",
        "            train[train['Country/Region'] == reg]['Country/Region'].unique())\n",
        "    return states_per_regions, unique_regions\n",
        "\n",
        "def convert_predictions_nc(res_nc, test, pivot_date, end_date):\n",
        "    test = test.query(\"Date>=\"+pivot_date)\n",
        "    test = test.query(\"Date<=\"+end_date)\n",
        "    index=dict()\n",
        "    for i in range(len(res_nc)):\n",
        "        index[res_nc.iloc[i]['Country/State'][0]]=i\n",
        "\n",
        "    pred_c, pred_d, pred_nc=[], [], []\n",
        "    for i in tqdm(range(len(test))):\n",
        "        if(test.iloc[i]['Country/Region'] in index):\n",
        "            loc=index[test.iloc[i]['Country/Region']]\n",
        "            date = datetime.datetime.strftime(test.iloc[i]['Date'].date(), format=\"%Y-%m-%d\")\n",
        "            pred_nc.append(res_nc.iloc[loc][date]) \n",
        "    \n",
        "    test['Infected'] = pred_nc\n",
        "   \n",
        "    res_regional=test\n",
        "    res=test.drop(columns=['Country/Region','Date'])\n",
        "    return res, res_regional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iE4-Ftua60w"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uza28-CLa600",
        "scrolled": true
      },
      "source": [
        "#ITALY - only hospitalized\n",
        "epochs = [20]\n",
        "batch_sizes = [8,12,6]\n",
        "n_hiddens = [50]\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "epoch = 30\n",
        "batch_size = 32\n",
        "n_hidden = 36\n",
        "num_days = 7\n",
        "\n",
        "MAE, MSE, RMSE, R2 = {}, {}, {}, {}\n",
        "target = \"Hospitalized\"\n",
        "\n",
        "for epoch in epochs:\n",
        "    for batch_size in batch_sizes:\n",
        "        for n_hidden in n_hiddens:\n",
        "          numdays = [7]\n",
        "          for num_days in numdays:\n",
        "            iteration = str(epoch) + \"/\" + str(batch_size) +  \"/\" + str(n_hidden) + \"/\" + str(num_days)\n",
        "            print(iteration)\n",
        "\n",
        "            train = train_df.rename(columns={'Fatal': 'Deaths', 'Date': 'ObservationDate'})\n",
        "            covid_timeseries = train.copy()\n",
        "\n",
        "            num_cols = ['Confirmed', 'Deaths']\n",
        "            for col in num_cols:\n",
        "                temp = [int(i) for i in train[col]]\n",
        "                train[col] = temp\n",
        "\n",
        "            # Create empty test set\n",
        "            dates = list(train.ObservationDate)\n",
        "\n",
        "            d = []\n",
        "            for date in dates:\n",
        "                d.append(\n",
        "                    {\n",
        "                        'Date': date\n",
        "                    })\n",
        "\n",
        "            test = pd.DataFrame(d)\n",
        "\n",
        "            # Number of steps to look back\n",
        "            n_steps = num_days\n",
        "\n",
        "            # Number of days to forcast\n",
        "            num_days = 10\n",
        "\n",
        "            pivot_date = \"'2021-03-15'\"\n",
        "\n",
        "            print('Hospitalized Cases')\n",
        "            X_h, y_h = my_create_train_dataset('Hospitalized', n_steps, train, pivot_date)\n",
        "            test_hospitalized = my_create_test_dataset('Hospitalized', n_steps, train, pivot_date)\n",
        "\n",
        "            # Split the train data in to train and val data\n",
        "            X_train_h, X_val_h, y_train_h, y_val_h = train_test_split(\n",
        "                X_h, y_h, test_size=0.30, random_state=42)\n",
        "\n",
        "            # Reshape data\n",
        "            test_h = pd.DataFrame(test_hospitalized).values\n",
        "            X_train_h = X_train_h.reshape((X_train_h.shape[0], 1, X_train_h.shape[1]))\n",
        "            X_val_h = X_val_h.reshape((X_val_h.shape[0], 1,  X_val_h.shape[1]))\n",
        "\n",
        "            X_test_h = test_h.reshape((test_h.shape[0], 1, test_h.shape[1]))\n",
        "\n",
        "            # Initializing model components\n",
        "            timesteps = X_train_h.shape[1]\n",
        "            input_dim = X_train_h.shape[2]\n",
        "            n_features = 1\n",
        "\n",
        "            # Model for infected\n",
        "            model_h = Sequential()\n",
        "            model_h.add(LSTM(n_hidden, activation='relu', input_shape=(n_features,n_steps),return_sequences=True))\n",
        "            model_h.add(LSTM(n_hidden, activation='relu'))\n",
        "            model_h.add(Dense(1))\n",
        "            model_h.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredLogarithmicError())\n",
        "            callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.6),\n",
        "                        EarlyStopping(monitor='val_loss', patience=20),\n",
        "                        ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "            hist=model_h.fit(X_train_h,y_train_h, epochs=epoch, batch_size=batch_size, validation_data=(X_val_h, y_val_h), verbose=2, shuffle=False,callbacks=callbacks)\n",
        "\n",
        "\n",
        "            forcast_start_date = pivot_date.replace(\"'\", \"\")\n",
        "            res_new_confirmed = my_forcast(model_h, X_test_h, forcast_start_date, num_days, n_steps )\n",
        "            begin_date = pivot_date\n",
        "            end_date = f\"'{res_new_confirmed.columns[-2:][0]}'\"\n",
        "\n",
        "            res_regional = my_convert_predictions(res_new_confirmed, test, begin_date, end_date)\n",
        "            maes, mses, rmses, r2s = [], [], [], []\n",
        "            Y_pred = res_regional\n",
        "            Y_true = train_df\n",
        "            temp = pd.merge(Y_true, Y_pred, on=\"Date\")\n",
        "            print(temp.columns)\n",
        "            y, yhat = temp[\"Hospitalized LSTM\"], temp[target]\n",
        "            maes.append(metrics.mean_absolute_error(y, yhat))\n",
        "            mses.append(metrics.mean_squared_error(y, yhat))\n",
        "            rmses.append(np.sqrt(metrics.mean_squared_error(y, yhat)))\n",
        "            r2s.append(metrics.r2_score(y,yhat))\n",
        "\n",
        "            #PRINT\n",
        "            MAE, MSE, RMSE, R2 = [], [], [], []\n",
        "            Y_pred = res_regional\n",
        "\n",
        "            predictions = []\n",
        "            for i in range(Y_pred.shape[0]):\n",
        "              prediction = str(list(Y_pred['Hospitalized LSTM'])[i])\n",
        "              prediction = re.split('\\s+', prediction)\n",
        "              true_pred = float(prediction[1])\n",
        "              predictions.append(true_pred)\n",
        "            Y_pred[\"Hospitalized LSTM\"] = predictions\n",
        "\n",
        "            Y_true_before = Y_true[Y_true[\"Date\"]<pivot_date]\n",
        "            Y_true_after = Y_true[Y_true[\"Date\"]>pivot_date]\n",
        "\n",
        "            fig, axs = plt.subplots(1,1,figsize=(5, 4), constrained_layout=True);\n",
        "            Y_pred.plot(x=\"Date\", y=\"Hospitalized LSTM\", label=\"H (LSTM forecast)\", color=\"blue\", ax=axs) \n",
        "            Y_true_before.plot(x=\"Date\", y=target, label=\"H (reported)\", ax=axs, color=\"magenta\");\n",
        "            Y_true_after.plot(x=\"Date\", y=target, ax=axs, color=\"magenta\",linestyle=\"dotted\", label = \"_ciao\");\n",
        "            axs.axvline(x=pivot_date, linestyle=\"--\", color=\"grey\")\n",
        "            axs.legend(loc=\"upper left\")\n",
        "            axs.set_facecolor('white')\n",
        "\n",
        "            axs.set_title(iteration + \"\\n Hospitalized\")\n",
        "  \n",
        "            fig.show()\n",
        "\n",
        "            temp = pd.merge(Y_true, Y_pred, on=\"Date\")\n",
        "            y, yhat = temp[\"Hospitalized LSTM\"], temp[target]\n",
        "\n",
        "            MAE.append(metrics.mean_absolute_error(y, yhat))\n",
        "            MSE.append(metrics.mean_squared_error(y, yhat))\n",
        "            RMSE.append(np.sqrt(metrics.mean_squared_error(y, yhat)))\n",
        "            R2.append(metrics.r2_score(y,yhat))\n",
        "\n",
        "            print(\"MAE\", np.mean(MAE))\n",
        "            print(\"MSE\", np.mean(MSE))\n",
        "            print(\"RMSE\", np.mean(RMSE))\n",
        "            print(\"R2\", np.mean(R2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvplavQfcP5Q"
      },
      "source": [
        "#WORLD\n",
        "epochs = [30] #, 50, 70]\n",
        "batch_sizes = [8] #[8, 12, 14]\n",
        "n_hiddens = [50]\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "epoch = 30\n",
        "batch_size = 32\n",
        "n_hidden = 36\n",
        "num_days = 5\n",
        "\n",
        "MAE, MSE, RMSE, R2 = {}, {}, {}, {}\n",
        "target = \"Infected\"\n",
        "countries = train_df[\"Country\"].unique()\n",
        "\n",
        "for epoch in epochs:\n",
        "    for batch_size in batch_sizes:\n",
        "        for n_hidden in n_hiddens:\n",
        "            numdays = [5]\n",
        "            for num_days in numdays:\n",
        "              iteration = str(epoch) + \"/\" + str(batch_size) +  \"/\" + str(n_hidden) + \"/\" + str(num_days)\n",
        "              print(iteration)\n",
        "\n",
        "              train = train_df.rename(columns={'Country': 'Country/Region','Fatal': 'Deaths', 'Date': 'ObservationDate'})\n",
        "              covid_timeseries = train.copy()\n",
        "\n",
        "              num_cols = ['Confirmed', 'Deaths']\n",
        "              for col in num_cols:\n",
        "                  temp = [int(i) for i in train[col]]\n",
        "                  train[col] = temp\n",
        "\n",
        "              # Create empty test set\n",
        "              countries = train[\"Country/Region\"].unique()\n",
        "              dates = list(train[train[\"Country/Region\"] == countries[0]].ObservationDate)\n",
        "\n",
        "              # Create empty test set\n",
        "              d = []\n",
        "              for country in countries:\n",
        "                  for date in dates:\n",
        "                      d.append(\n",
        "                          {\n",
        "                              'Country/Region': country,\n",
        "                              'Date': date,\n",
        "                          }\n",
        "                      )\n",
        "              test = pd.DataFrame(d)\n",
        "\n",
        "              states_per_regions, unique_regions = list_per_region(test)\n",
        "\n",
        "              # Number of steps to look back\n",
        "              n_steps = num_days\n",
        "\n",
        "              # Number of days to forcast\n",
        "              num_days = 10\n",
        "\n",
        "              pivot_date = \"'2021-03-20'\"\n",
        "\n",
        "\n",
        "              print('Infected Cases')\n",
        "              X_i, y_i = create_train_dataset('Infected', n_steps, train, pivot_date, unique_regions, states_per_regions)\n",
        "              test_infected, regs = create_test_dataset('Infected', n_steps, train, pivot_date, unique_regions, states_per_regions)\n",
        "\n",
        "              print('Recovered Cases')\n",
        "              X_r, y_r = create_train_dataset('Recovered', n_steps, train, pivot_date, unique_regions, states_per_regions)\n",
        "              test_recovered, regs = create_test_dataset('Recovered', n_steps, train, pivot_date, unique_regions, states_per_regions)\n",
        "\n",
        "              print('Deaths Cases')\n",
        "              X_d, y_d = create_train_dataset('Deaths', n_steps, train, pivot_date, unique_regions, states_per_regions)\n",
        "              test_deaths, regs = create_test_dataset('Deaths', n_steps, train, pivot_date, unique_regions, states_per_regions)\n",
        "              print('Finished preparing datasets.')\n",
        "\n",
        "              # Split the train data in to train and val data\n",
        "              X_train_d, X_val_d, y_train_d, y_val_d = train_test_split(\n",
        "                  X_d, y_d, test_size=0.30, random_state=42)\n",
        "              X_train_i, X_val_i, y_train_i, y_val_i = train_test_split(\n",
        "                  X_i, y_i, test_size=0.30, random_state=42)\n",
        "              X_train_r, X_val_r, y_train_r, y_val_r = train_test_split(\n",
        "                  X_r, y_r, test_size=0.30, random_state=42)\n",
        "\n",
        "              # Reshape data\n",
        "\n",
        "              test_d = pd.DataFrame(test_deaths).values\n",
        "              test_r = pd.DataFrame(test_recovered).values\n",
        "              test_i = pd.DataFrame(test_infected).values\n",
        "\n",
        "\n",
        "              # Reshapping the Confirmed data for LSTM\n",
        "\n",
        "              X_train_i = X_train_i.reshape((X_train_i.shape[0], 1, X_train_i.shape[1]))\n",
        "              X_val_i = X_val_i.reshape((X_val_i.shape[0], 1,  X_val_i.shape[1]))\n",
        "\n",
        "              X_train_r = X_train_r.reshape((X_train_r.shape[0], 1, X_train_r.shape[1]))\n",
        "              X_val_r = X_val_r.reshape((X_val_r.shape[0], 1,  X_val_r.shape[1]))\n",
        "\n",
        "              X_train_d = X_train_d.reshape((X_train_d.shape[0], 1, X_train_d.shape[1]))\n",
        "              X_val_d = X_val_d.reshape((X_val_d.shape[0], 1,  X_val_d.shape[1]))\n",
        "\n",
        "              X_test_i = test_i.reshape((test_i.shape[0], 1, test_i.shape[1]))\n",
        "              X_test_r = test_r.reshape((test_r.shape[0], 1, test_r.shape[1]))\n",
        "              X_test_d = test_d.reshape((test_d.shape[0], 1, test_d.shape[1]))\n",
        "\n",
        "              # Initializing model components\n",
        "              timesteps = X_train_i.shape[1]\n",
        "              input_dim = X_train_i.shape[2]\n",
        "              n_features = 1\n",
        "\n",
        "              # Model for Death cases\n",
        "              #model_d = Sequential()\n",
        "              #model_d.add(LSTM(50, activation='relu', input_shape=(n_features,n_steps),return_sequences=True))\n",
        "              #model_d.add(LSTM(50, activation='relu'))\n",
        "              #model_d.add(Dense(batch_size)) #MLP\n",
        "              #model_d.add(Dense(1))\n",
        "              #model_d.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredLogarithmicError())\n",
        "              #callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.6),\n",
        "                #                EarlyStopping(monitor='val_loss', patience=20),\n",
        "                #              ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "              #hist=model_d.fit(X_train_d,y_train_d, epochs=epoch, batch_size=batch_size, validation_data=(X_val_d, y_val_d), verbose=2, shuffle=False,callbacks=callbacks)\n",
        "\n",
        "              # Model for new confirmed cases\n",
        "              model_nc = Sequential()\n",
        "              model_nc.add(LSTM(n_hidden, activation='relu', input_shape=(n_features,n_steps),return_sequences=True))\n",
        "              model_nc.add(LSTM(n_hidden, activation='relu'))\n",
        "              model_nc.add(Dense(batch_size)) #MLP\n",
        "              model_nc.add(Dense(1))\n",
        "\n",
        "              model_nc.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredLogarithmicError())\n",
        "              callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.6),\n",
        "                        EarlyStopping(monitor='val_loss', patience=20),\n",
        "                         ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "              hist=model_nc.fit(X_train_i,y_train_i, epochs=epoch, batch_size=batch_size, validation_data=(X_val_i, y_val_i), verbose=2, shuffle=False,callbacks=callbacks)\n",
        "\n",
        "\n",
        "              forcast_start_date = pivot_date.replace(\"'\", \"\")\n",
        "              #     res_confirmed=forcast(model_c,X_test_c,forcast_start_date, num_days, n_steps, regs)\n",
        "              #     res_deaths=forcast(model_d,X_test_d,forcast_start_date, num_days, n_steps, regs)\n",
        "              res_new_confirmed = forcast(model_nc,X_test_i,forcast_start_date, num_days, n_steps, regs)\n",
        "\n",
        "              begin_date = pivot_date\n",
        "              end_date = f\"'{res_new_confirmed.columns[-2:][0]}'\"\n",
        "\n",
        "              #     sub, res_regional = convert_predictions_df(res_confirmed, res_deaths, res_new_confirmed, test,begin_date, end_date)\n",
        "              sub, res_regional = convert_predictions_nc(res_new_confirmed, test, begin_date, end_date)\n",
        "              res_regional = res_regional.rename(columns={\"Infected\": \"Infected LSTM\"})\n",
        "              maes, mses, rmses, r2s = [], [], [], []\n",
        "              country = \"Italy\"\n",
        "              #     try:\n",
        "              Y_pred = res_regional[res_regional[\"Country/Region\"] == country]\n",
        "              Y_true = train_df[train_df[\"Country\"] == country]\n",
        "              temp = pd.merge(Y_true, Y_pred, on=\"Date\")\n",
        "              y, yhat = temp[target + \" LSTM\"], temp[target]\n",
        "              maes.append(metrics.mean_absolute_error(y, yhat))\n",
        "              mses.append(metrics.mean_squared_error(y, yhat))\n",
        "              rmses.append(np.sqrt(metrics.mean_squared_error(y, yhat)))\n",
        "              r2s.append(metrics.r2_score(y,yhat))\n",
        "\n",
        "              MAE, MSE, RMSE, R2 = [], [], [], []\n",
        "              target = \"Infected\"\n",
        "              # res_regional = res_regional.rename(columns={\"Confirmed\": \"Confirmed_LSTM\", \"New Confirmed\": \"New Confirmed_LSTM\", \"Deaths\": \"Deaths_LSTM\"})\n",
        "              # res_regional = res_regional.rename(columns={\"New Confirmed\": \"New Confirmed_LSTM\"})\n",
        "\n",
        "              Y_pred = res_regional[res_regional[\"Country/Region\"] == \"Italy\"]\n",
        "              Y_true_before = Y_true[Y_true[\"Date\"]<pivot_date]\n",
        "              Y_true_after = Y_true[Y_true[\"Date\"]>pivot_date]\n",
        "\n",
        "              fig, axs = plt.subplots(1,1,figsize=(5, 4), constrained_layout=True);\n",
        "              Y_pred.plot(x=\"Date\", y=\"Infected LSTM\", label=\"I (LSTM forecast)\", color=\"blue\", ax=axs) \n",
        "              Y_true_before.plot(x=\"Date\", y=target, label=\"I (reported)\", ax=axs, color=\"green\");\n",
        "              Y_true_after.plot(x=\"Date\", y=target, ax=axs, color=\"green\",linestyle=\"dotted\", label = \"_ciao\");\n",
        "              axs.axvline(x=pivot_date, linestyle=\"--\", color=\"grey\")\n",
        "              axs.legend(loc=\"upper left\")\n",
        "              axs.set_facecolor('white')\n",
        "              axs.set_title(iteration + \"\\n Infected\")\n",
        "  \n",
        "              fig.show()\n",
        "\n",
        "              temp = pd.merge(Y_true, Y_pred, on=\"Date\")\n",
        "              y, yhat = temp[\"Infected LSTM\"], temp[target]\n",
        "                  \n",
        "              MAE.append(metrics.mean_absolute_error(y, yhat))\n",
        "              MSE.append(metrics.mean_squared_error(y, yhat))\n",
        "              RMSE.append(np.sqrt(metrics.mean_squared_error(y, yhat)))\n",
        "              R2.append(metrics.r2_score(y,yhat))\n",
        "                  \n",
        "              print(\"MAE\", np.mean(MAE))\n",
        "              print(\"MSE\", np.mean(MSE))\n",
        "              print(\"RMSE\", np.mean(RMSE))\n",
        "              print(\"R2\", np.mean(R2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm39Unhq_dRj"
      },
      "source": [
        "# Infected forecast\n",
        "# 30 ep, 8 batc + MLP, 5 window\n",
        "pred_list = []\n",
        "n_input_i = 5\n",
        "n_features = 1\n",
        "\n",
        "train_italy_i = train_df[train_df[\"Country\"]==\"Italy\"]\n",
        "dates = list(train_italy[\"Date\"])\n",
        "train_i = train_italy_i.drop(columns =[\"Fatal\", \"Recovered\", \"New Confirmed\", \"Confirmed\", \"Country\"])\n",
        "train_predicted_i =train_i.copy()\n",
        "\n",
        "start_date = str(dates[-1])\n",
        "date1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
        "last_index = train_predicted_i.index[-1]\n",
        "\n",
        "pred_i = train_predicted_i.loc[last_index, \"Infected\"]\n",
        "day = 0 \n",
        "for day in range(690):\n",
        "  day +=1\n",
        "  ts_i = train_predicted_i[\"Infected\"].values\n",
        "  batch_i = ts_i[-n_input_i:].reshape((1 , n_features, n_input_i)) \n",
        "  date1 += relativedelta(days=1)\n",
        "  date_pred = date1.strftime(\"%Y-%m-%d\")\n",
        "  date_pred = datetime.datetime.strptime(date_pred, \"%Y-%m-%d\")\n",
        "  pred_i = model_nc.predict(batch_i)[0][0]\n",
        "  new_index = last_index + day\n",
        "  train_predicted_i.loc[new_index] = {\"Infected\": pred_i, \"Date\": date_pred}\n",
        "\n",
        "Y_true_before_i = train_predicted_i[train_predicted_i[\"Date\"]<\"2021-03-30\"]\n",
        "Y_true_after_i = train_predicted_i[train_predicted_i[\"Date\"]>\"2021-03-30\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk1M1Me53PDi"
      },
      "source": [
        "# Deaths forecast\n",
        "pred_list = []\n",
        "n_input_d = 10\n",
        "n_features_d = 1\n",
        "\n",
        "train_italy_d = train_df[train_df[\"Country\"]==\"Italy\"]\n",
        "dates_d = list(train_italy_d[\"Date\"])\n",
        "train_d = train_italy_d.drop(columns =[\"Infected\", \"Recovered\", \"New Confirmed\", \"Confirmed\", \"Country\"])\n",
        "train_predicted_d =train_d.copy()\n",
        "\n",
        "start_date = str(dates[-1])\n",
        "date1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
        "last_index = train_predicted_d.index[-1]\n",
        "\n",
        "pred_d = train_predicted_d.loc[last_index, \"Fatal\"]\n",
        "day =0 \n",
        "for day in range(690):\n",
        "  day +=1\n",
        "  ts_d = train_predicted_d[\"Fatal\"].values\n",
        "  batch_d = ts_d[-n_input_d:].reshape((1 , n_features_d, n_input_d)) \n",
        "  date1 += relativedelta(days=1)\n",
        "  date_pred = date1.strftime(\"%Y-%m-%d\")\n",
        "  date_pred = datetime.datetime.strptime(date_pred, \"%Y-%m-%d\")\n",
        "  pred_d = model_d.predict(batch_d)[0][0]\n",
        "  new_index =last_index + day\n",
        "  train_predicted_d.loc[new_index] = {\"Fatal\": pred_d, \"Date\": date_pred}\n",
        "  \n",
        "Y_true_before_d = train_predicted_d[train_predicted_d[\"Date\"]<\"2021-03-30\"]\n",
        "Y_true_after_d = train_predicted_d[train_predicted_d[\"Date\"]>\"2021-03-30\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUHH9ggv6buL"
      },
      "source": [
        "# Hospitalized forecast\n",
        "n_input_h = 7\n",
        "n_features = 1\n",
        "\n",
        "train_italy_h = train_df.copy()\n",
        "dates = list(train_italy_h[\"Date\"])\n",
        "train_h = train_italy_h.drop(columns =[\"Infected\", \"Fatal\", \"Recovered\", \"New Confirmed\", \"Confirmed\"])\n",
        "train_predicted_h =train_h.copy()\n",
        "\n",
        "start_date = str(dates[-1])\n",
        "date1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
        "last_index = train_predicted_h.index[-1]\n",
        "\n",
        "pred_h = train_predicted_h.loc[last_index, \"Hospitalized\"]\n",
        "day =0 \n",
        "for day in range(600):\n",
        "  day +=1\n",
        "  ts_h = train_predicted_h[\"Hospitalized\"].values\n",
        "  batch_h = ts_h[-n_input_h:].reshape((1 , n_features, n_input_h)) \n",
        "  date1 += relativedelta(days=1)\n",
        "  date_pred = date1.strftime(\"%Y-%m-%d\")\n",
        "  date_pred = datetime.datetime.strptime(date_pred, \"%Y-%m-%d\")\n",
        "  pred_h = model_h.predict(batch_h)[0][0]\n",
        "  new_index =last_index + day\n",
        "  train_predicted_h.loc[new_index] = {\"Hospitalized\": pred_h, \"Date\": date_pred}\n",
        "\n",
        "Y_true_before_h = train_predicted_h[train_predicted_h[\"Date\"]<\"2021-03-30\"]\n",
        "Y_true_after_h = train_predicted_h[train_predicted_h[\"Date\"]>\"2021-03-30\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9rVdtQ_II6o"
      },
      "source": [
        "#PLOT INFECTED\n",
        "fig, axs = plt.subplots(1,1,figsize=(5,4), constrained_layout=True);\n",
        "Y_true_before_i.plot(x=\"Date\", y=\"Infected\", label=\"I (reported)\", ax=axs, color=\"green\");\n",
        "Y_true_after_i.plot(x=\"Date\", y=\"Infected\", ax=axs, color=\"green\",linestyle=\"dotted\", label = \"I (forecast)\");\n",
        "axs.axvline(x=\"2021-03-30\", linestyle=\"--\", color=\"grey\")\n",
        "axs.set_title(\"LSTM model forecast\")\n",
        "axs.set_xlabel(\"Days\")\n",
        "axs.set_ylabel(\"Number of individuals\")\n",
        "axs.legend(loc=\"upper right\")\n",
        "axs.set_facecolor('white')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9olUH5jx5g4u"
      },
      "source": [
        "#PLOT DEATHS FORECAST\n",
        "# 20 ep, 16 batch, no MLP, time window 10\n",
        "fig, axs = plt.subplots(1,1,figsize=(5,4), constrained_layout=True);\n",
        "Y_true_before_d.plot(x=\"Date\", y=\"Fatal\", label=\"D (reported)\", ax=axs, color=\"black\");\n",
        "Y_true_after_d.plot(x=\"Date\", y=\"Fatal\", ax=axs, color=\"black\", linestyle=\"dotted\",label = \"D (forecast)\");\n",
        "axs.axvline(x=\"2021-03-30\", linestyle=\"--\", color=\"grey\")\n",
        "axs.set_title(\"LSTM model forecast\")\n",
        "axs.set_xlabel(\"Days\")\n",
        "axs.set_ylabel(\"Number of individuals\")\n",
        "axs.legend(loc=\"upper left\")\n",
        "axs.set_facecolor('white')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}